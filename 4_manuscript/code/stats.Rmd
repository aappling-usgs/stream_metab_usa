---
title: "Statistics for Manuscript"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---
 
```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(readr)
```

Load data from cached data release files.
```{r, message=FALSE}
dailies_zip='../../4_data_release/cache/models/post/daily_predictions.zip'
diagnostics_rds='../../4_data_release/cache/models/diagnostics.rds'

stats_tmp_dir <- file.path(tempdir(), 'stats')
unzipped <- list(
  dailies = unzip(zipfile=dailies_zip, exdir=stats_tmp_dir)
)
dailies <- readr::read_tsv(unzipped$dailies)
diagnostics <- readRDS(diagnostics_rds)
```

Dates per site
```{r}
dates_per_site <- dailies %>% group_by(site_name) %>% count()
range(dates_per_site$n) # 61 3296
max(dates_per_site$n)/365.25 # 9.02
median(dates_per_site$n)/365.25 # 3.229295
mean(dates_per_site$n)/365.25 # 3.775365
```

Total number of dates
```{r}
nrow(dailies) # 490907
```

Dates by resolution
```{r}
dates_by_resolution <- dailies %>% group_by(resolution) %>% count()
```

Higher temporal resolution leads to longer runtime
```{r}
ggplot(diagnostics, aes(x=n_dates, y=run_hrs, color=resolution)) + geom_point() + geom_smooth(method='lm') + facet_wrap(~ saved_steps)
```

Higher resolution appears to reduce probability of non-convergence, as measured by whether we re-ran the model
```{r}
diagnostics %>%
  mutate(res = as.integer(gsub('min','',resolution))) %>%
  group_by(res) %>%
  summarize(
    ss_500 = length(which(saved_steps == 500)),
    ss_2000 = length(which(saved_steps == 2000)),
    frac_rerun = ss_2000/(ss_500+ss_2000))
# res ss_500 ss_2000 frac_rerun
#   5     17       1     0.0556
#  12      1       1     0.500 
#  15    213      83     0.280 
#  30     34      24     0.414 
#  60     23      36     0.610 
```

Some measures of total, average, and median runtime
```{r}
diagnostics %>% 
  mutate(hrs_per_year_bymodel=365.25*run_hrs/n_dates) %>%
  summarize(
    run_hrs=sum(run_hrs),
    run_days=run_hrs/24,
    n_dates=sum(n_dates),
    hrs_per_year_q05=quantile(hrs_per_year_bymodel, probs=0.05),
    hrs_per_year_q50=quantile(hrs_per_year_bymodel, probs=0.50),
    hrs_per_year_q95=quantile(hrs_per_year_bymodel, probs=0.95),
    hrs_per_year=365.25*run_hrs/n_dates
  )
```

Determine which data sources were used for each timeseries as inputs to the models
```{r}
config <- read_tsv('../../4_data_release/cache/models/config.tsv')
src_cols <- grep('.src', names(config), fixed=TRUE, value=TRUE)
src_counts <- bind_rows(lapply(setNames(nm=src_cols), function(metab_var_src) {
  counts <- table(config[[metab_var_src]])
  metab__var <- gsub('.src', '', metab_var_src, fixed=TRUE)
  data_frame(variable=metab__var, var=mda.streams::get_var_src_codes(metab_var==metab__var)$var[1],
             src=names(counts), var_src=paste(var, src, sep='_'), count=unname(counts))
}))
src_counts
```
